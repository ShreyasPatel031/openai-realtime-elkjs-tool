(node:83904) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:
--import 'data:text/javascript,import { register } from "node:module"; import { pathToFileURL } from "node:url"; register("ts-node/esm", pathToFileURL("./"));'
(Use `node --trace-warnings ...` to show where the warning was created)
🔧 Initialized 5 OpenAI client instances
WebSocket server error: Port is already in use
🚀 Server running at http://localhost:3006
Browserslist: browsers data (caniuse-lite) is 7 months old. Please run:
  npx update-browserslist-db@latest
  Why you should do it regularly: https://github.com/browserslist/update-db#readme
=== STREAM REQUEST ===
Method: POST
Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryggT4eAU3MJFDcyVu
🔍 [req-1753222504759-7zea3j08a] Stream request received
🔍 [req-1753222504759-7zea3j08a] Request headers: {
  'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',
  origin: 'http://localhost:3006',
  referer: 'http://localhost:3006/',
  connection: 'keep-alive'
}
🔍 [req-1753222504759-7zea3j08a] Original conversation length: 2
🔍 [req-1753222504759-7zea3j08a] Cleaned conversation length: 2
🔍 [req-1753222504759-7zea3j08a] Payload structure being sent to OpenAI: {
  "messages": [
    {
      "role": "system",
      "content": "string",
      "hasResponseId": false,
      "hasRsId": false
    },
    {
      "role": "user",
      "content": "string",
      "hasResponseId": false,
      "hasRsId": false
    }
  ],
  "hasResponseIds": false,
  "originalResponseIds": []
}
📸 Processing 1 uploaded image(s)...
📸 Image 1 details:
  - Original filename: pasted-image-1753222504038.png
  - MIME type: image/png
  - Buffer size: 87813 bytes
  - Base64 data preview: data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA+wAAAI0CAYAAACHw6N+AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKg...
📸 Added image 1 to conversation
🔄 Starting conversation turn with 2 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753222504763-a6abbycya with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 0,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753222504763-a6abbycya (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
⚠️ Client disconnected (req.close)
✅ Request req-1753222504763-a6abbycya completed successfully
🔍 [req-1753222504759-7zea3j08a] OpenAI stream created successfully
🎯 Processing function call: display_elk_graph
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 5 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753222800626-5rcu61vxy with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 1,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753222800626-5rcu61vxy (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 5,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753222800626-5rcu61vxy completed successfully
🔍 [req-1753222504759-7zea3j08a] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 8 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753222820209-gx1r2zswi with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 2,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753222820209-gx1r2zswi (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 8,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
6:20:20 PM [vite] Pre-transform error: Failed to load url /assets/canvas/entry-client.jsx (resolved id: /assets/canvas/entry-client.jsx). Does the file exist?
✅ Request req-1753222820209-gx1r2zswi completed successfully
🔍 [req-1753222504759-7zea3j08a] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 11 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753222835209-gq95ynhup with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 3,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753222835209-gq95ynhup (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 11,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753222835209-gq95ynhup completed successfully
🔍 [req-1753222504759-7zea3j08a] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 14 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753222843359-p5sqdlv5c with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 4,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753222843359-p5sqdlv5c (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 14,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753222843359-p5sqdlv5c completed successfully
🔍 [req-1753222504759-7zea3j08a] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 17 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753222849337-e05yhf5rs with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 5,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753222849337-e05yhf5rs (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 17,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753222849337-e05yhf5rs completed successfully
🔍 [req-1753222504759-7zea3j08a] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 20 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753222856717-mu6ti9rze with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 6,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753222856717-mu6ti9rze (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 20,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753222856717-mu6ti9rze completed successfully
🔍 [req-1753222504759-7zea3j08a] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 23 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753222864777-z79pun0fg with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 7,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753222864777-z79pun0fg (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 23,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753222864777-z79pun0fg completed successfully
🔍 [req-1753222504759-7zea3j08a] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 26 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753222871214-2qsqobibp with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 8,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753222871214-2qsqobibp (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 26,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753222871214-2qsqobibp completed successfully
🔍 [req-1753222504759-7zea3j08a] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 29 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753222906928-zfz0jj3qm with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 9,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753222906928-zfz0jj3qm (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 29,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753222906928-zfz0jj3qm completed successfully
🔍 [req-1753222504759-7zea3j08a] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 32 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753222921461-w3ut5mwg2 with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 10,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753222921461-w3ut5mwg2 (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 32,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753222921461-w3ut5mwg2 completed successfully
🔍 [req-1753222504759-7zea3j08a] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 35 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753222938422-y69gozhsu with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 11,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753222938422-y69gozhsu (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 35,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753222938422-y69gozhsu completed successfully
🔍 [req-1753222504759-7zea3j08a] OpenAI stream created successfully
⚠️ Response stream closed (res.close)
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 35 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753222944546-00u7g0ihk with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 12,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753222944546-00u7g0ihk (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 35,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753222944546-00u7g0ihk completed successfully
🔍 [req-1753222504759-7zea3j08a] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 35 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753222945960-fy41apx61 with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 13,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753222945960-fy41apx61 (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 35,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753222945960-fy41apx61 completed successfully
🔍 [req-1753222504759-7zea3j08a] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 35 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753222947886-h50lx1mcx with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 14,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753222947886-h50lx1mcx (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 35,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753222947886-h50lx1mcx completed successfully
🔍 [req-1753222504759-7zea3j08a] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 35 items
🔍 [req-1753222504759-7zea3j08a] Creating OpenAI stream request...
📥 Queued request req-1753223075798-r2tia03fb with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 15,
  failedRequests: 0,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753223075798-r2tia03fb (1/3 active)
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 35,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
⚠️ Request failed (attempt 1), retrying in 1000ms: Request timed out.
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 35,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
⚠️ Request failed (attempt 2), retrying in 2000ms: Connection error.
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 35,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
⚠️ Request failed (attempt 3), retrying in 4000ms: Connection error.
🔍 [req-1753222504759-7zea3j08a] Using tools: 10 functions
🔍 [req-1753222504759-7zea3j08a] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 35,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
❌ Request req-1753223075798-r2tia03fb failed: Connection error.
❌ OpenAI API Error: APIConnectionError: Connection error.
    at OpenAI.makeRequest (file:///Users/shreyaspatel/Desktop/Code/openai-realtime-console/node_modules/openai/core.mjs:325:19)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async ConnectionManager.executeWithRetry (file:///Users/shreyaspatel/Desktop/Code/openai-realtime-console/server/connectionManager.js:146:16)
    at async ConnectionManager.executeRequest (file:///Users/shreyaspatel/Desktop/Code/openai-realtime-console/server/connectionManager.js:123:22) {
  status: undefined,
  headers: undefined,
  request_id: undefined,
  error: undefined,
  code: undefined,
  param: undefined,
  type: undefined,
  cause: FetchError: request to https://api.openai.com/v1/responses failed, reason: getaddrinfo ENOTFOUND api.openai.com
      at ClientRequest.<anonymous> (/Users/shreyaspatel/Desktop/Code/openai-realtime-console/node_modules/openai/node_modules/node-fetch/lib/index.js:1501:11)
      at ClientRequest.emit (node:events:524:28)
      at emitErrorEvent (node:_http_client:101:11)
      at TLSSocket.socketErrorListener (node:_http_client:504:5)
      at TLSSocket.emit (node:events:536:35)
      at emitErrorNT (node:internal/streams/destroy:169:8)
      at emitErrorCloseNT (node:internal/streams/destroy:128:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    type: 'system',
    errno: 'ENOTFOUND',
    code: 'ENOTFOUND'
  }
}
=== STREAM REQUEST ===
Method: POST
Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryArxIu8yJFw6elnTd
🔍 [req-1753227883118-3p20majlu] Stream request received
🔍 [req-1753227883118-3p20majlu] Request headers: {
  'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',
  origin: 'http://localhost:3006',
  referer: 'http://localhost:3006/',
  connection: 'keep-alive'
}
🔍 [req-1753227883118-3p20majlu] Original conversation length: 2
🔍 [req-1753227883118-3p20majlu] Cleaned conversation length: 2
🔍 [req-1753227883118-3p20majlu] Payload structure being sent to OpenAI: {
  "messages": [
    {
      "role": "system",
      "content": "string",
      "hasResponseId": false,
      "hasRsId": false
    },
    {
      "role": "user",
      "content": "string",
      "hasResponseId": false,
      "hasRsId": false
    }
  ],
  "hasResponseIds": false,
  "originalResponseIds": []
}
📸 Processing 1 uploaded image(s)...
📸 Image 1 details:
  - Original filename: pasted-image-1753227882925.png
  - MIME type: image/png
  - Buffer size: 124231 bytes
  - Base64 data preview: data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABZgAAAKhCAYAAADdf8svAAAAAXNSR0IArs4c6QAAAERlWElmTU0AKg...
📸 Added image 1 to conversation
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753227883125-r25k4z6to with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 15,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753227883125-r25k4z6to (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
⚠️ Client disconnected (req.close)
✅ Request req-1753227883125-r25k4z6to completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Response stream closed (res.close)
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753227992746-34wg9pf8w with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 16,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753227992746-34wg9pf8w (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753227992746-34wg9pf8w completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753227993358-3yishi6us with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 17,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753227993358-3yishi6us (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753227993358-3yishi6us completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753227993656-5zxfnkmlq with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 18,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753227993656-5zxfnkmlq (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753227993656-5zxfnkmlq completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753227994201-cvmulcuqa with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 19,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753227994201-cvmulcuqa (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753227994201-cvmulcuqa completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753227994545-49993uz1l with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 20,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753227994545-49993uz1l (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753227994545-49993uz1l completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753227995094-8hunrm9ak with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 21,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753227995094-8hunrm9ak (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753227995094-8hunrm9ak completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753227995452-31640q205 with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 22,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753227995452-31640q205 (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753227995452-31640q205 completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753227995813-y78npkdnx with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 23,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753227995813-y78npkdnx (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753227995813-y78npkdnx completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753227996426-kxfhllcor with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 24,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753227996426-kxfhllcor (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753227996426-kxfhllcor completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753227996990-56xa32con with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 25,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753227996990-56xa32con (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753227996990-56xa32con completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753227997363-5i5srxdco with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 26,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753227997363-5i5srxdco (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753227997363-5i5srxdco completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753227998720-aqa5auhiw with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 27,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753227998720-aqa5auhiw (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753227998720-aqa5auhiw completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228000144-2eruc1rc4 with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 28,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228000144-2eruc1rc4 (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228000144-2eruc1rc4 completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228001192-2kvimcb4e with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 29,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228001192-2kvimcb4e (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228001192-2kvimcb4e completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228002244-jmm0dpnz1 with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 30,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228002244-jmm0dpnz1 (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228002244-jmm0dpnz1 completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228003289-tx339m8xi with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 31,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228003289-tx339m8xi (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228003289-tx339m8xi completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228003658-o2r5jt69w with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 32,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228003658-o2r5jt69w (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228003658-o2r5jt69w completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228004516-ehhohx9fi with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 33,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228004516-ehhohx9fi (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228004516-ehhohx9fi completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228006250-lqzikxfwu with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 34,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228006250-lqzikxfwu (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228006250-lqzikxfwu completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228007896-206chqk78 with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 35,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228007896-206chqk78 (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228007896-206chqk78 completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228009202-0iyb0sw80 with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 36,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228009202-0iyb0sw80 (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228009202-0iyb0sw80 completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228010877-i621rhl4e with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 37,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228010877-i621rhl4e (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228010877-i621rhl4e completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228011589-1sxl0x0rd with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 38,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228011589-1sxl0x0rd (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228011589-1sxl0x0rd completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228012008-st9indw95 with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 39,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228012008-st9indw95 (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228012008-st9indw95 completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228012589-9oo2d1r9c with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 40,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228012589-9oo2d1r9c (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
⚠️ Request failed (attempt 1), retrying in 1000ms: Connection error.
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
⚠️ Request failed (attempt 2), retrying in 2000ms: Connection error.
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228012589-9oo2d1r9c completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228016300-7gz1wwuag with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 41,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228016300-7gz1wwuag (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228016300-7gz1wwuag completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228016740-thy4lrpt1 with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 42,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228016740-thy4lrpt1 (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228016740-thy4lrpt1 completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228017321-dl7hlc04g with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 43,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228017321-dl7hlc04g (1/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
=== STREAM REQUEST ===
Method: POST
Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryTDwb9it4cT8qDnKq
🔍 [req-1753228018219-fwn8ehhbi] Stream request received
🔍 [req-1753228018219-fwn8ehhbi] Request headers: {
  'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',
  origin: 'http://localhost:3006',
  referer: 'http://localhost:3006/',
  connection: 'keep-alive'
}
🔍 [req-1753228018219-fwn8ehhbi] Original conversation length: 2
🔍 [req-1753228018219-fwn8ehhbi] Cleaned conversation length: 2
🔍 [req-1753228018219-fwn8ehhbi] Payload structure being sent to OpenAI: {
  "messages": [
    {
      "role": "system",
      "content": "string",
      "hasResponseId": false,
      "hasRsId": false
    },
    {
      "role": "user",
      "content": "string",
      "hasResponseId": false,
      "hasRsId": false
    }
  ],
  "hasResponseIds": false,
  "originalResponseIds": []
}
📸 Processing 1 uploaded image(s)...
📸 Image 1 details:
  - Original filename: pasted-image-1753228017912.png
  - MIME type: image/png
  - Buffer size: 87813 bytes
  - Base64 data preview: data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA+wAAAI0CAYAAACHw6N+AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKg...
📸 Added image 1 to conversation
🔄 Starting conversation turn with 2 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228018220-tw30anjux with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 1,
  queuedRequests: 1,
  completedRequests: 43,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228018220-tw30anjux (2/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
⚠️ Client disconnected (req.close)
✅ Request req-1753228017321-dl7hlc04g completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
🔄 Starting conversation turn with 2 items
🔍 [req-1753227883118-3p20majlu] Creating OpenAI stream request...
📥 Queued request req-1753228018824-s2ca4cosa with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 1,
  queuedRequests: 1,
  completedRequests: 44,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228018824-s2ca4cosa (2/3 active)
🔍 [req-1753227883118-3p20majlu] Using tools: 10 functions
🔍 [req-1753227883118-3p20majlu] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 2,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228018824-s2ca4cosa completed successfully
🔍 [req-1753227883118-3p20majlu] OpenAI stream created successfully
⚠️ Client disconnected during stream - stopping
⚠️  Reached maximum turns (30), ending conversation
✅ Request req-1753228018220-tw30anjux completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: display_elk_graph
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 5 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228400832-ytxrw8uaz with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 46,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228400832-ytxrw8uaz (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 5,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228400832-ytxrw8uaz completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 7 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228405631-bpj6fzhmq with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 47,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228405631-bpj6fzhmq (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 7,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
7:53:25 PM [vite] Pre-transform error: Failed to load url /assets/canvas/entry-client.jsx (resolved id: /assets/canvas/entry-client.jsx). Does the file exist?
✅ Request req-1753228405631-bpj6fzhmq completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 9 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228415969-5y44w0k8r with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 48,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228415969-5y44w0k8r (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 9,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228415969-5y44w0k8r completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 11 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228425601-qkcrvvt1p with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 49,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228425601-qkcrvvt1p (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 11,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228425601-qkcrvvt1p completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 14 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228436454-j2iox1uvn with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 50,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228436454-j2iox1uvn (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 14,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
⚠️ Request failed (attempt 1), retrying in 1000ms: Connection error.
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 14,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228436454-j2iox1uvn completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 16 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228439933-xrtjrb7zn with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 51,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228439933-xrtjrb7zn (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 16,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228439933-xrtjrb7zn completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 19 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228444850-b7hk8egle with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 52,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228444850-b7hk8egle (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 19,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228444850-b7hk8egle completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: display_elk_graph
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 21 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228446693-wvnvgm3zd with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 53,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228446693-wvnvgm3zd (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 21,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228446693-wvnvgm3zd completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
⚠️  No function calls in this turn (1/2)
🔄 Allowing agent to continue thinking...
🔄 Starting conversation turn with 22 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228448540-sba5lm5wg with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 54,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228448540-sba5lm5wg (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 22,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228448540-sba5lm5wg completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 25 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228464566-6a0pzmdp0 with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 55,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228464566-6a0pzmdp0 (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 25,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228464566-6a0pzmdp0 completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: display_elk_graph
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 28 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228475170-5y5m77i4k with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 56,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228475170-5y5m77i4k (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 28,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228475170-5y5m77i4k completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 30 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228479766-6f3e13tjv with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 57,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228479766-6f3e13tjv (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 30,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228479766-6f3e13tjv completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 32 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228483419-e1xvfcm95 with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 58,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228483419-e1xvfcm95 (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 32,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228483419-e1xvfcm95 completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 35 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228490282-szaqpvxnm with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 59,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228490282-szaqpvxnm (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 35,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228490282-szaqpvxnm completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 38 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228498821-mmp0h0n2i with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 60,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228498821-mmp0h0n2i (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 38,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228498821-mmp0h0n2i completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 40 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228501113-r9ydad0yu with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 61,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228501113-r9ydad0yu (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 40,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228501113-r9ydad0yu completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 43 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228506685-ikar1sx5a with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 62,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228506685-ikar1sx5a (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 43,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228506685-ikar1sx5a completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: display_elk_graph
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 45 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228509363-cn3lgcuaj with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 63,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228509363-cn3lgcuaj (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 45,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228509363-cn3lgcuaj completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
⚠️  No function calls in this turn (1/2)
🔄 Allowing agent to continue thinking...
🔄 Starting conversation turn with 46 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228511760-o8gfkzuht with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 64,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228511760-o8gfkzuht (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 46,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228511760-o8gfkzuht completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: display_elk_graph
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 49 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228522017-orob1hidb with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 65,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228522017-orob1hidb (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 49,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228522017-orob1hidb completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 51 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228526371-27whesjja with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 66,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228526371-27whesjja (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 51,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228526371-27whesjja completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 53 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228530868-uflx5vxsx with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 67,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228530868-uflx5vxsx (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 53,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228530868-uflx5vxsx completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 56 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228538652-47kjb9ivw with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 68,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228538652-47kjb9ivw (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 56,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228538652-47kjb9ivw completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 59 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228552273-6gjbabok3 with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 69,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228552273-6gjbabok3 (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 59,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228552273-6gjbabok3 completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
🎯 Processing function call: batch_update
🔄 1 function call(s) processed, continuing conversation loop
🔄 Starting conversation turn with 61 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228554450-dkn0x62kf with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 70,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228554450-dkn0x62kf (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 61,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228554450-dkn0x62kf completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
⚠️  No function calls in this turn (1/2)
🔄 Allowing agent to continue thinking...
🔄 Starting conversation turn with 63 items
🔍 [req-1753228018219-fwn8ehhbi] Creating OpenAI stream request...
📥 Queued request req-1753228557388-v4plhk0ee with priority high (1 in queue)
🔍 ConnectionManager: Current state: {
  activeRequests: 0,
  queuedRequests: 1,
  completedRequests: 71,
  failedRequests: 1,
  totalClients: 5,
  maxConcurrentRequests: 3
}
🚀 Executing request req-1753228557388-v4plhk0ee (1/3 active)
🔍 [req-1753228018219-fwn8ehhbi] Using tools: 10 functions
🔍 [req-1753228018219-fwn8ehhbi] Final request payload to OpenAI: {
  model: 'o3',
  inputMessages: 63,
  tools: 10,
  tool_choice: 'auto',
  parallel_tool_calls: true,
  reasoning: { effort: 'high', summary: 'detailed' },
  stream: true
}
✅ Request req-1753228557388-v4plhk0ee completed successfully
🔍 [req-1753228018219-fwn8ehhbi] OpenAI stream created successfully
⚠️  No function calls in this turn (2/2)
✅ Conversation complete - no more function calls needed or completion indicated
⚠️ Response stream closed (res.close)
